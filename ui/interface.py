import streamlit as st

# --- 2. CSS Ä°LE ZORLA GENÄ°ÅLETME (Paddingleri alma) ---
st.markdown(
    """
    <style>
        /* 1. SayfanÄ±n ana bloÄŸundaki boÅŸluklarÄ± al ve %100 yap */
        .block-container {
            padding-top: 1rem !important;
            padding-bottom: 1rem !important;
            padding-left: 1rem !important;
            padding-right: 1rem !important;
            max-width: 100% !important;
        }

        /* 2. Sidebar geniÅŸliÄŸini sabitle */
        [data-testid="stSidebar"] {
            min-width: 350px !important;
            max-width: 350px !important;
        }
        
        /* 3. DataFrame ve Grafikleri tam boy yap */
        .stDataFrame, .stPlotlyChart {
            width: 100% !important;
        }
    </style>
    """,
    unsafe_allow_html=True
)

import pandas as pd
import plotly.express as px
import time
import numpy as np
import joblib
import os
from data_pipeline.loader import load_data
from data_pipeline.preprocessing import clean_data, scale_features, handle_missing_values
from model_factory.trainers import get_model
from evaluation.comparisons import train_and_evaluate
from visualization.charts import plot_confusion_matrix_heatmap, plot_feature_importance_bar
from sklearn.model_selection import train_test_split
import plotly.graph_objects as go


# --- 2. TÃœRKÃ‡E SÃ–ZLÃœK ---
tr_labels = {
    'baseline value': 'Temel Kalp HÄ±zÄ± (Normal: 110-160)',
    'accelerations': 'HÄ±zlanmalar (Ä°yi: > 0.003)',
    'fetal_movement': 'Bebek Hareket SayÄ±sÄ±',
    'uterine_contractions': 'Rahim KasÄ±lmalarÄ± (0.0 - 0.015)',
    'light_decelerations': 'Hafif YavaÅŸlamalar',
    'severe_decelerations': 'Åiddetli YavaÅŸlamalar',
    'prolongued_decelerations': 'Uzun YavaÅŸlamalar (Normal: 0.0)',
    'abnormal_short_term_variability': 'Anormal KÄ±sa DÃ¶nem DeÄŸiÅŸkenlik (Normal: < 60)',
    'mean_value_of_short_term_variability': 'KÄ±sa DÃ¶nem DeÄŸiÅŸkenlik OrtalamasÄ±',
    'percentage_of_time_with_abnormal_long_term_variability': 'Anormal Uzun DÃ¶nem DeÄŸiÅŸkenlik %',
    'mean_value_of_long_term_variability': 'Uzun DÃ¶nem DeÄŸiÅŸkenlik OrtalamasÄ±',
    'histogram_width': 'Histogram GeniÅŸliÄŸi',
    'histogram_min': 'Histogram Min DeÄŸer',
    'histogram_max': 'Histogram Max DeÄŸer',
    'histogram_number_of_peaks': 'Histogram Tepe NoktasÄ±',
    'histogram_number_of_zeroes': 'Histogram SÄ±fÄ±r SayÄ±sÄ±',
    'histogram_mode': 'Histogram Mod (Tepe DeÄŸer)',
    'histogram_mean': 'Histogram Ortalama',
    'histogram_median': 'Histogram Medyan',
    'histogram_variance': 'Histogram VaryansÄ±',
    'histogram_tendency': 'Histogram EÄŸilimi'
}

# --- YARDIMCI FONKSÄ°YON: GAUGE CHART ---
def create_gauge_chart(title, value, color_code):
    fig = go.Figure(go.Indicator(
        mode = "gauge+number",
        value = value,
        domain = {'x': [0, 1], 'y': [0, 1]},
        title = {'text': title, 'font': {'size': 18}},
        number = {'suffix': "%", 'font': {'size': 24}}, 
        gauge = {
            'axis': {'range': [None, 100], 'tickwidth': 1, 'tickcolor': "white"},
            'bar': {'color': color_code}, 
            'bgcolor': "rgba(0,0,0,0)",
            'borderwidth': 2,
            'bordercolor': "#e0e0e0",
            'steps': [
                {'range': [0, 100], 'color': "#f0f0f0"}
            ],
            'shape': "angular", 
        }
    ))
    fig.update_layout(autosize=True, height=180, margin=dict(l=20, r=20, t=50, b=20), paper_bgcolor="rgba(0,0,0,0)", font={'color': "#333"})
    return fig

# --- YARDIMCI FONKSÄ°YONLAR ---
def try_load_model(silent=False):
    current_dir = os.getcwd()
    file_path = os.path.join(current_dir, "champion_model.pkl")
    
    if os.path.exists(file_path):
        try:
            model_data = joblib.load(file_path)
            st.session_state['best_model'] = model_data['model']
            st.session_state['scaler'] = model_data['scaler']
            st.session_state['best_model_name'] = model_data['name']
            st.session_state['best_accuracy'] = model_data['accuracy']
            if 'X_test' in model_data: st.session_state['last_X_test'] = model_data['X_test']
            if 'y_test' in model_data: st.session_state['last_y_test'] = model_data['y_test']
            if 'feature_names' in model_data: st.session_state['feature_names'] = model_data['feature_names']
            if 'results_df' in model_data: st.session_state['last_results'] = model_data['results_df']
            
            if not silent: return True, f"{model_data['name']} ({file_path})"
            return True, "Oto YÃ¼kleme BaÅŸarÄ±lÄ±"
        except Exception as e: return False, str(e)
    return False, "Dosya bulunamadÄ±."

@st.cache_data
def get_data():
    df = load_data("data/fetal_health.csv")
    return clean_data(df)

# --- 3. ANA FONKSÄ°YON ---
def run_ui():
    keys_to_init = {
        'best_model': None, 'best_model_name': "", 'best_accuracy': 0.0,
        'scaler': None, 'last_results': None, 'last_X_test': None,
        'last_y_test': None, 'feature_names': None, 'auto_loaded': False
    }
    for key, val in keys_to_init.items():
        if key not in st.session_state:
            st.session_state[key] = val

    if not st.session_state['auto_loaded']:
        success, msg = try_load_model(silent=True)
        if success:
            st.toast(f"ğŸš€ HazÄ±r Model Otomatik YÃ¼klendi: {st.session_state['best_model_name']}", icon="âœ…")
        st.session_state['auto_loaded'] = True
    
    st.title("ğŸ¥ Fetal SaÄŸlÄ±k - Yapay Zeka ArenasÄ±")
    
    st.sidebar.header("Navigasyon")
    page = st.sidebar.selectbox("ModÃ¼l SeÃ§iniz", ["1. Veri Analizi", "2. Model KÄ±yaslama (Toplu EÄŸitim)", "3. CanlÄ± Tahmin"])
    
    st.sidebar.markdown("---")
    st.sidebar.header("ğŸ’¾ Model Durumu")
    
    if st.session_state.get('best_model'):
        st.sidebar.success(f"âœ… AKTÄ°F: **{st.session_state['best_model_name']}**")
        st.sidebar.info(f"BaÅŸarÄ± Skoru: **%{st.session_state['best_accuracy']*100:.2f}**")
        if st.sidebar.button("ğŸ”„ Dosyadan Tekrar YÃ¼kle"):
            success, msg = try_load_model()
            if success:
                st.sidebar.success("YÃ¼klendi!")
                time.sleep(1)
                st.rerun()
    else:
        st.sidebar.warning("HenÃ¼z model yok.")
        if st.sidebar.button("ğŸ“‚ KayÄ±tlÄ± Modeli Ara ve YÃ¼kle"):
            success, msg = try_load_model()
            if success: st.rerun()

    df = get_data()
    
    if page == "1. Veri Analizi":
        show_data_analysis(df)
    elif page == "2. Model KÄ±yaslama (Toplu EÄŸitim)":
        show_model_comparison(df)
    elif page == "3. CanlÄ± Tahmin":
        show_prediction(df)

def show_data_analysis(df):
    st.header("ğŸ“Š Veri Seti Analizi")
    show_all = st.checkbox("TÃ¼m verileri gÃ¶ster", value=False)
    
    if show_all:
        st.dataframe(df, use_container_width=True)
    else:
        st.dataframe(df.head(7), use_container_width=True)
        st.caption("VarsayÄ±lan olarak ilk 7 satÄ±r gÃ¶steriliyor.")

    col1, col2 = st.columns(2)
    col1.info(f"Toplam Veri SayÄ±sÄ±: {df.shape[0]}")
    col2.info(f"Toplam Ã–zellik (SÃ¼tun): {df.shape[1]}")
    
    fig_target = px.histogram(df, x="fetal_health", color="fetal_health", title="SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ± (1: Normal, 2: ÅÃ¼pheli, 3: Patolojik)")
    st.plotly_chart(fig_target, use_container_width=True)

def show_model_comparison(df):
    st.header("ğŸ† Algoritma KÄ±yaslama ArenasÄ±")
    
    if st.session_state.get('best_model') is not None:
        st.success(f"ğŸ“‚ HafÄ±zadaki Åampiyon: **{st.session_state['best_model_name']}** (BaÅŸarÄ±: %{st.session_state['best_accuracy']*100:.2f})")
        col_save, col_info = st.columns([1, 2])
        with col_save:
            if st.button("ğŸ’¾ BU MODELÄ° VE GRAFÄ°KLERÄ° DÄ°SKE KAYDET", type="primary", use_container_width=True):
                try:
                    current_dir = os.getcwd()
                    file_path = os.path.join(current_dir, "champion_model.pkl")
                    save_package = {
                        'model': st.session_state['best_model'],
                        'scaler': st.session_state['scaler'],
                        'name': st.session_state['best_model_name'],
                        'accuracy': st.session_state['best_accuracy'],
                        'X_test': st.session_state.get('last_X_test'),
                        'y_test': st.session_state.get('last_y_test'),
                        'feature_names': st.session_state.get('feature_names'),
                        'results_df': st.session_state.get('last_results')
                    }
                    joblib.dump(save_package, file_path)
                    st.balloons()
                    st.success(f"âœ… KayÄ±t BaÅŸarÄ±lÄ±!")
                except Exception as e: st.error(f"Hata: {e}")

    if st.session_state.get('last_results') is not None:
        st.markdown("---")
        st.subheader("ğŸ“Š SonuÃ§ Tablosu")
        results_df = st.session_state['last_results']
        col_table, col_graph = st.columns([1, 1])
        with col_table:
            st.dataframe(results_df.style.background_gradient(subset=["Accuracy"], cmap="Greens").format({"Accuracy": "{:.2%}", "F1": "{:.2%}", "Time": "{:.4f}"}), use_container_width=True)
        with col_graph:
            fig = px.bar(results_df, x="Model", y="Accuracy", color="Model", title="Model BaÅŸarÄ± KarÅŸÄ±laÅŸtÄ±rmasÄ±")
            fig.update_layout(showlegend=False)
            st.plotly_chart(fig, use_container_width=True)

        if st.session_state.get('best_model') and st.session_state.get('last_X_test') is not None:
            st.markdown("---")
            st.subheader(f"ğŸ§  {st.session_state['best_model_name']} - DetaylÄ± Performans Analizi")
            tab1, tab2 = st.tabs(["Hata Matrisi", "Ã–zellik Ã–nemi"])
            with tab1:
                y_pred = st.session_state['best_model'].predict(st.session_state['last_X_test'])
                fig_cm = plot_confusion_matrix_heatmap(st.session_state['last_y_test'], y_pred, labels=['Normal', 'ÅÃ¼pheli', 'Patolojik'])
                st.plotly_chart(fig_cm, use_container_width=True)
            with tab2:
                fig_feat = plot_feature_importance_bar(st.session_state['best_model'], st.session_state['feature_names'], tr_labels)
                if fig_feat: st.plotly_chart(fig_feat, use_container_width=True)
                else: st.info("Bu model iÃ§in Ã¶zellik Ã¶nem grafiÄŸi desteklenmiyor.")

    st.markdown("---")
    st.subheader("Yeni Turnuva BaÅŸlat")
    col_set1, col_set2, col_set3 = st.columns(3)
    n_runs = col_set1.slider("Tur SayÄ±sÄ±", 1, 100, 5) 
    test_size = col_set2.slider("Test OranÄ± (%)", 10, 50, 20) / 100
    missing_strategy = col_set3.radio("Eksik Veri Stratejisi", ["mean", "median", "drop"], index=1)
    
    models_to_test = ["Random Forest", "SVM", "XGBoost", "Logistic Regression", "Decision Tree"]
    selected_models = st.multiselect("Modelleri SeÃ§", models_to_test, default=models_to_test)

    if st.button("ğŸ”¥ TURNUVAYI BAÅLAT", use_container_width=True):
        if not selected_models:
            st.error("Model seÃ§melisin!")
            return

        progress_bar = st.progress(0)
        status_text = st.empty()
        results_list = []
        
        X = df.drop('fetal_health', axis=1)
        y = df['fetal_health'] - 1 
        feature_names_list = X.columns.tolist() 
        X = handle_missing_values(X, strategy=missing_strategy)
        
        global_best_acc = 0
        global_best_model = None
        global_best_name = ""
        global_scaler = None
        final_X_test_scaled = None
        final_y_test = None

        total_steps = len(selected_models) * n_runs
        current_step = 0

        for model_name in selected_models:
            accuracies = []
            f1_scores = []
            times = []
            temp_X_test_scaled = None
            temp_y_test = None
            temp_model = None
            temp_scaler = None

            for i in range(n_runs):
                status_text.text(f"â³ {model_name} eÄŸitiliyor ({i+1}/{n_runs})...")
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)
                X_train_scaled, scaler = scale_features(X_train, method="Standard")
                X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)
                
                temp_X_test_scaled = X_test_scaled
                temp_y_test = y_test
                temp_scaler = scaler
                
                model = get_model(model_name)
                res = train_and_evaluate(model, X_train_scaled, X_test_scaled, y_train, y_test)
                
                accuracies.append(res['Accuracy'])
                f1_scores.append(res['F1 Score'])
                times.append(res['Training Time (sec)'])
                temp_model = res['Model']
                current_step += 1
                progress_bar.progress(current_step / total_steps)
            
            avg_acc = np.mean(accuracies)
            results_list.append({"Model": model_name, "Accuracy": avg_acc, "F1": np.mean(f1_scores), "Time": np.mean(times), "Tur SayÄ±sÄ±": n_runs})
            
            if avg_acc > global_best_acc:
                global_best_acc = avg_acc
                global_best_model = temp_model
                global_best_name = model_name
                global_scaler = temp_scaler
                final_X_test_scaled = temp_X_test_scaled
                final_y_test = temp_y_test

        progress_bar.empty()
        status_text.success("Turnuva TamamlandÄ±!")
        res_df = pd.DataFrame(results_list).sort_values(by="Accuracy", ascending=False)
        
        st.session_state['best_model'] = global_best_model
        st.session_state['best_model_name'] = global_best_name
        st.session_state['best_accuracy'] = global_best_acc
        st.session_state['scaler'] = global_scaler
        st.session_state['last_results'] = res_df 
        st.session_state['last_X_test'] = final_X_test_scaled
        st.session_state['last_y_test'] = final_y_test
        st.session_state['feature_names'] = feature_names_list
        st.rerun()

def show_prediction(df):
    st.header("ğŸ©º CanlÄ± Tahmin")
    if st.session_state.get('best_model') is None:
        st.error("âš ï¸ Model YÃ¼klÃ¼ DeÄŸil!")
        return

    model = st.session_state['best_model']
    scaler = st.session_state['scaler']
    st.success(f"Aktif Model: {st.session_state['best_model_name']}")

    class_means = df.groupby('fetal_health').mean()
    col_demo1, col_demo2 = st.columns(2)
    with col_demo1:
        if st.button("âœ… SaÄŸlÄ±klÄ± DeÄŸerleri Doldur", use_container_width=True):
            healthy_data = class_means.loc[1.0]
            for col in healthy_data.index: st.session_state[f"input_{col}"] = healthy_data[col]
            st.rerun()

    with col_demo2:
        if st.button("ğŸš¨ Hasta (Patolojik) DeÄŸerleri Doldur"):
            sick_data = class_means.loc[3.0]
            for col in sick_data.index:
                st.session_state[f"input_{col}"] = sick_data[col]
            
            st.session_state["input_abnormal_short_term_variability"] = 78.0
            st.session_state["input_prolongued_decelerations"] = 0.005 
            st.session_state["input_accelerations"] = 0.000
            st.session_state["input_baseline value"] = 100.0
            st.session_state["input_histogram_mean"] = 100.0
            st.session_state["input_histogram_median"] = 100.0
            st.session_state["input_histogram_mode"] = 100.0
            st.session_state["input_histogram_min"] = 90.0
            st.session_state["input_histogram_max"] = 110.0
            st.session_state["input_histogram_width"] = 20.0
            st.rerun()
            
    st.markdown("---")
    use_sync = st.checkbox("ğŸ”— Otomatik TutarlÄ±lÄ±k (Histogram Matematiksel EÅŸitleme)", value=False)
    input_values = {}
    original_columns = df.drop('fetal_health', axis=1).columns
    main_cols = ['baseline value', 'accelerations', 'uterine_contractions', 'prolongued_decelerations', 'abnormal_short_term_variability']
    other_cols = [c for c in original_columns if c not in main_cols]
    
    col1, col2 = st.columns(2)
    with col1:
        col_name = main_cols[0] 
        label = tr_labels.get(col_name, col_name)
        def_val = st.session_state.get(f"input_{col_name}", float(df[col_name].median()))
        new_baseline = st.number_input(label, value=float(def_val), key=f"input_{col_name}")
        input_values[col_name] = new_baseline
        if use_sync:
            input_values['histogram_mean'] = new_baseline
            input_values['histogram_median'] = new_baseline
            input_values['histogram_mode'] = new_baseline
            input_values['histogram_min'] = max(0, new_baseline - 10)
            input_values['histogram_max'] = new_baseline + 10
            new_width = input_values['histogram_max'] - input_values['histogram_min']
            input_values['histogram_width'] = new_width
            st.session_state['input_histogram_mean'] = input_values['histogram_mean']
            st.session_state['input_histogram_median'] = input_values['histogram_median']
            st.session_state['input_histogram_mode'] = input_values['histogram_mode']
            st.session_state['input_histogram_min'] = input_values['histogram_min']
            st.session_state['input_histogram_max'] = input_values['histogram_max']
            st.session_state['input_histogram_width'] = input_values['histogram_width']
    
        for col_name in main_cols[1:3]: 
             label = tr_labels.get(col_name, col_name)
             def_val = st.session_state.get(f"input_{col_name}", float(df[col_name].median()))
             input_values[col_name] = st.number_input(label, value=float(def_val), format="%.4f", key=f"input_{col_name}")
    with col2:
        for col_name in main_cols[3:]:
             label = tr_labels.get(col_name, col_name)
             def_val = st.session_state.get(f"input_{col_name}", float(df[col_name].median()))
             input_values[col_name] = st.number_input(label, value=float(def_val), format="%.4f", key=f"input_{col_name}")

    with st.expander("ğŸ”¬ DetaylÄ± Veriler (Histogram, Varyans vb.)", expanded=True):
        cols = st.columns(4)
        for i, col_name in enumerate(other_cols):
            with cols[i % 4]:
                label = tr_labels.get(col_name, col_name)
                if use_sync and col_name in ['histogram_mean', 'histogram_median', 'histogram_mode', 'histogram_min', 'histogram_max', 'histogram_width']:
                     val_to_show = input_values.get(col_name, 0)
                     st.number_input(label, value=float(val_to_show), key=f"disp_{col_name}", disabled=True)
                     input_values[col_name] = val_to_show
                else:
                    def_val = st.session_state.get(f"input_{col_name}", float(df[col_name].median()))
                    val = st.number_input(label, value=float(def_val), key=f"input_{col_name}")
                    input_values[col_name] = val

    if st.button("ğŸ” TAHMÄ°N ET", type="primary", use_container_width=True):
        input_df = pd.DataFrame([input_values])
        input_df = input_df[original_columns]
        input_scaled = pd.DataFrame(scaler.transform(input_df), columns=original_columns)
        pred = model.predict(input_scaled)[0]
        
        st.markdown("---")
        if pred == 0.0: st.success("ğŸŸ¢ SONUÃ‡: NORMAL")
        elif pred == 1.0: st.warning("ğŸŸ¡ SONUÃ‡: ÅÃœPHELÄ°")
        else: st.error("ğŸ”´ SONUÃ‡: PATOLOJÄ°K (RÄ°SKLÄ°)")
        
        if hasattr(model, "predict_proba"):
            probs = model.predict_proba(input_scaled)[0]
            
            # --- OLASILIK DAÄILIMI (GAUGE CHARTS) ---
            st.markdown("### ğŸ¯ OlasÄ±lÄ±k DaÄŸÄ±lÄ±mÄ± (GÃ¼ven OranÄ±)")
            col_g1, col_g2, col_g3 = st.columns(3)
            
            with col_g1:
                st.plotly_chart(create_gauge_chart("ğŸŸ¢ Normal", probs[0]*100, "#2ecc71"), use_container_width=True)
            with col_g2:
                st.plotly_chart(create_gauge_chart("ğŸŸ¡ ÅÃ¼pheli", probs[1]*100, "#f1c40f"), use_container_width=True)
            with col_g3:
                st.plotly_chart(create_gauge_chart("ğŸ”´ Patolojik", probs[2]*100, "#e74c3c"), use_container_width=True)
        
        # --- KARAR ANALÄ°ZÄ°: NEDEN BU SONUÃ‡ Ã‡IKTI? (YENÄ°LENEN KISIM) ---
        st.markdown("---")
        st.subheader("ğŸ•µï¸ Karar Analizi: Neden Bu SonuÃ§ Ã‡Ä±ktÄ±?")
        
        # Sadece Tree-based modellerde (XGBoost, RandomForest vb.) Ã§alÄ±ÅŸÄ±r
        if hasattr(model, "feature_importances_"):
            import numpy as np
            
            # 1. Modelin genel Ã¶zellik Ã¶nemleri
            importances = model.feature_importances_
            
            # 2. Girilen hastanÄ±n deÄŸerlerinin 'Normalden Sapma' miktarÄ±
            # input_scaled iÃ§inde 0 demek 'tam ortalama' demek.
            # Mutlak deÄŸer alÄ±yoruz ki eksi veya artÄ± yÃ¶nde aÅŸÄ±rÄ± sapmalarÄ± yakalayalÄ±m.
            input_impact = np.abs(input_scaled.values[0])
            
            # 3. HÄ°BRÄ°T SKOR: (Ã–nem x Sapma)
            # Hem model iÃ§in Ã¶nemli olacak HEM DE hasta bu konuda uÃ§ deÄŸerde olacak.
            contribution = importances * input_impact
            
            # EÄŸer tÃ¼m deÄŸerler ortalamaysa (0 ise) hata vermesin diye minik bir sayÄ± ekle
            if contribution.sum() == 0: contribution += 1e-9
                
            # 4. YÃ¼zdeye Ã‡evirme (%30 buradan, %20 ÅŸuradan...)
            contribution_pct = (contribution / contribution.sum()) * 100
            
            # 5. DataFrame HazÄ±rlÄ±ÄŸÄ±
            reason_df = pd.DataFrame({
                'Ã–zellik': original_columns,
                'Etki YÃ¼zdesi': contribution_pct,
                'Ham Ã–nem': importances,
                'Hasta DeÄŸeri (Scaled)': input_impact
            })
            
            # TÃ¼rkÃ§e Ä°simlendirme
            reason_df['Ã–zellik Ä°smi'] = reason_df['Ã–zellik'].apply(lambda x: tr_labels.get(x, x))
            
            # En etkili 5 sebebi al
            reason_df = reason_df.sort_values(by='Etki YÃ¼zdesi', ascending=False).head(5)
            
            col_reason1, col_reason2 = st.columns([1, 1])
            
            with col_reason1:
                # PASTA GRAFÄ°ÄÄ° (DONUT)
                fig_pie = px.pie(
                    reason_df, 
                    values='Etki YÃ¼zdesi', 
                    names='Ã–zellik Ä°smi',
                    title=f"Bu KararÄ± Etkileyen En BÃ¼yÃ¼k 5 FaktÃ¶r",
                    hole=0.4, # OrtasÄ± delik olsun (Donut)
                    color_discrete_sequence=px.colors.sequential.RdBu
                )
                fig_pie.update_traces(textposition='inside', textinfo='percent+label')
                fig_pie.update_layout(showlegend=False, margin=dict(t=40, b=0, l=0, r=0), height=300)
                st.plotly_chart(fig_pie, use_container_width=True)
                
            with col_reason2:
                # YANINA AÃ‡IKLAMA YAZALIM
                top_feature = reason_df.iloc[0]['Ã–zellik Ä°smi']
                top_pct = reason_df.iloc[0]['Etki YÃ¼zdesi']
                
                st.info(f"ğŸ’¡ **Yapay Zeka Diyor ki:**\n\n"
                        f"VerdiÄŸim kararda en bÃ¼yÃ¼k etken **%{top_pct:.1f}** oranÄ±yla\n"
                        f"**'{top_feature}'** verisindeki anormalliktir.\n\n"
                        f"Bu hastanÄ±n bu deÄŸeri, normal standartlarÄ±n dÄ±ÅŸÄ±na Ã§Ä±kmÄ±ÅŸ ve kararÄ± tetiklemiÅŸ.")
                
                st.dataframe(
                    reason_df[['Ã–zellik Ä°smi', 'Etki YÃ¼zdesi']].style.format({'Etki YÃ¼zdesi': '%{:.1f}'}),
                    use_container_width=True,
                    hide_index=True
                )

        else:
            st.warning("Bu model tÃ¼rÃ¼ (Ã–rn: SVM) detaylÄ± etki analizini desteklemiyor.")